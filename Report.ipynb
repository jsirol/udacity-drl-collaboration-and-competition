{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition - Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementation Details\n",
    "The implementation consists of files agent.py, model.py and ddpg_trainer.py found under the ddpg/ folder. The code is organized as follows:\n",
    "\n",
    "`agent.py` contains code for the agent.\n",
    "\n",
    "`model.py` contains the neural network code that is used by the agent.\n",
    "\n",
    "`ddpg_trainer.py` contains code that is used to train the agent.\n",
    "For information about the project and the environment can be found in the file `README.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm\n",
    "I re-used the Deep Deterministic Policy Gradient (DDPG)-code from Project 2 in the Udacity Deep Reinforcement Learning course as this was sufficient to solve this environment easily. The original code template implementing the DDPG-algorithm from the Udacity course Deep Reinforcement Learning was used as the starting point of Project 2 and hence also this Project. My work extended the template provided by Udacity by \n",
    "\n",
    "1. Collecting experiences from multiple agents (as there are two agents in the environment). \n",
    "2. Using different neural networks for the Actor and Critic, including Batch Normalization.\n",
    "\n",
    "The local and target networks were initialized using the same weights (one set of weights for Actor networks and one for the Critic networks). Also I did not use Ornstein-Uhlenbeck noise for the actions.\n",
    "\n",
    "As the agents in this environment have the same task of keeping the ball in play, and their observations are local, we will be using the same actor network for choosing actions for both of the Agents. The Critic network is naturally shared, too. Considering this setup, the DDPG where each agent adds its experience to the replay buffer is enough to\n",
    "\n",
    "### Learning process\n",
    "The algorithm uses two neural networks, the Actor that learns the optimal policy, and the Critic that learns the Q-function. The algorithm implements this as 4 neural networks, by having a local and a target network for both the Actor and Critic to stabilize learning.\n",
    "\n",
    "The networks are training using collected (s,a,r,s') experience tuples from 20 agents, that are stored into a replay buffer. At regular intervals, we train the model by sampling tuples from the replay buffer and applying gradient based updates to the network weights. For more details see the further reading-section.\n",
    "\n",
    "### Agent hyperparameters\n",
    "| parameter                                     | value |\n",
    "|-----------------------------------------------|-------|\n",
    "| experience replay buffer size                 | 1e5   |\n",
    "| minibatch size                                | 128   |\n",
    "| gamma (discount factor)                       | 0.999 |\n",
    "| tau (for soft update of target networks)      | 1e-3  |\n",
    "| learning rate Actor                           | 2e-4  |\n",
    "| learning rate Critic                          | 2e-4  |\n",
    "| L2 weight decay (for optimizers)              | 0     |\n",
    "| update_every (steps between networks updates) | 1     |\n",
    "| update_times (number of consecutive/step)     | 1     |\n",
    "\n",
    "### Neural network architecture\n",
    "\n",
    "#### Actor\n",
    "We used a neural network with 2 fully connected layers with ReLU activation and 128 hidden units. For the output layer we used tanh activation to scale the outputs to range (-1,1). We also applied Batch Normalization to the output of the first hidden layer.\n",
    "\n",
    "#### Critic\n",
    "Here we use again a neural network with 2 fully connected layers with ReLU activation and 128 hidden units. The first hidden layer takes the states as inputs. After applying non-linearity after after the 1st hidden layer, we concatenate the actions to the layer that feeds into the 2nd hidden layer. We applied Batch Normalization to the output of the first hidden layer (before we concatenate the actions, refer to the code in `model.py`).\n",
    "\n",
    "We don't use activation function for the output layer as we are learning a Q-function.\n",
    "\n",
    "\n",
    "### Further reading\n",
    "[Continuous control with deep reinforcement learning (original paper on DDPG)](https://arxiv.org/pdf/1509.02971.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "Below we train the model until the environment is solved or max 3000 iterations. The environment is solved in 1158 iterations, after which we train it further 200 iterations to see if we can get better performance than what is required as the solving criterion. \n",
    "\n",
    "We are forcing CPU computation in our implementation as we saw it trained faster for these small network architectures. If you want to run on a GPU instead, uncomment the line `torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")` in `agent.py`. \n",
    "\n",
    "If you want to watch a trained agent play, skip to part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ddpg.agent import Agent\n",
    "from ddpg.ddpg_trainer import train_ddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# get handle to the environment\n",
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\", no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "brain = env.brains[brain_name]\n",
    "states = env_info.vector_observations\n",
    "\n",
    "# environment metadata\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = states.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action size: 2\n",
      "State size: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Action size: {}\".format(action_size))\n",
    "print(\"State size: {}\".format(state_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the agent\n",
    "agent = Agent(state_size, action_size, random_seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 200\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 300\tAverage Score: 0.02\tScore: 0.00\n",
      "Episode 400\tAverage Score: 0.01\tScore: 0.00\n",
      "Episode 500\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 600\tAverage Score: 0.03\tScore: 0.00\n",
      "Episode 700\tAverage Score: 0.03\tScore: 0.00\n",
      "Episode 800\tAverage Score: 0.07\tScore: 0.00\n",
      "Episode 900\tAverage Score: 0.08\tScore: 0.10\n",
      "Episode 1000\tAverage Score: 0.10\tScore: 0.10\n",
      "Episode 1100\tAverage Score: 0.14\tScore: 0.20\n",
      "Episode 1158\tAverage Score: 0.50\tScore: 2.60\n",
      "Environment solved in 1158 episodes!\n",
      "\n",
      "Episode 1200\tAverage Score: 1.27\tScore: 0.20\n",
      "Episode 1300\tAverage Score: 1.74\tScore: 0.10\n",
      "Episode 1357\tAverage Score: 1.55\tScore: 0.10"
     ]
    }
   ],
   "source": [
    "# Train the agent for max 3000 episodes\n",
    "scores = train_ddpg(agent, env, n_episodes=3000, max_t=2000, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Plot of training rewards\n",
    "The blue line shows the score (maximum over the agents) per episode, the orange line the average of 100 consecutive episodes, and the red horizontal line indicates the criterion used for solving (i.e. +0.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1560220be10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)\n",
    "plt.plot(pd.Series(scores).rolling(100, min_periods=1).mean(), linewidth=2)\n",
    "plt.hlines(y=0.5, xmin=0, xmax=1400, linewidth=2, color='r')\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Watch the agent play (with pretrained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ddpg.agent import Agent\n",
    "\n",
    "\n",
    "# get handle to the environment (with graphics)\n",
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\", no_graphics=True)\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "brain = env.brains[brain_name]\n",
    "states = env_info.vector_observations\n",
    "\n",
    "# environment metadata\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = states.shape[1]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the agent\n",
    "agent = Agent(state_size, action_size, random_seed=1234)\n",
    "\n",
    "# load saved model weights (load last checkpoint as it had best average results)\n",
    "agent.actor_local.load_state_dict(torch.load(\"saved_models/best_actor.pth\"))\n",
    "agent.critic_local.load_state_dict(torch.load(\"saved_models/best_critic.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.600000038743019\n"
     ]
    }
   ],
   "source": [
    "# Watch agent play\n",
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")\n",
    "agent_scores = np.zeros(2) # initialize the scores\n",
    "agent.reset()\n",
    "\n",
    "# default brain\n",
    "brain_name = env.brain_names[0]\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "while True:\n",
    "        actions = agent.act(states)\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "        states = next_states\n",
    "        agent_scores += rewards\n",
    "        if np.any(dones):\n",
    "            break\n",
    "\n",
    "    \n",
    "print(\"Score: {}\".format(np.max(agent_scores)))\n",
    "# close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future work\n",
    "The DDPG algorithm seemed to work quite well with the same hyperparameters and network architectures as in Project 2. Also the play of the agents looks quite good. I noticed the rate of convergence varied a bit over different runs, where the environment was usually solved still under 2000 episodes. Thus I think most of the work could be done in optimizing the convergence of the algorithm, even though the wall time used for solving the environment was not too much. Also, still late in training some low scores are gained on individual runs.\n",
    "\n",
    "A few concrete ideas for future work include again prioritized experience replay and more thorough hyperparameter search could be used for this purpose. Also it would be interesting to try a different algorithm such as [PPO](https://arxiv.org/pdf/1707.06347.pdf), [A3C](https://arxiv.org/pdf/1602.01783.pdf) or [D4PG](https://openreview.net/pdf?id=SyZipzbCb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
